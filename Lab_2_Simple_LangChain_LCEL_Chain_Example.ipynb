{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rizabukhari/Agentic-AI-Pathway/blob/main/Lab_2_Simple_LangChain_LCEL_Chain_Example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7UD0sNgttG1M"
      },
      "source": [
        "# Simple LangChain LCEL Chain Example\n",
        "\n",
        "This notebook shows how to create a simple LLM Chain using LangChain's new LangChain Expression Language (LCEL) syntax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19XTN_hMiBZY"
      },
      "source": [
        "## Install Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzXw3x6be5JH"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install langchain #==0.3.11\n",
        "!pip install langchain-openai #==0.2.12"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5pyPRU4iVOy"
      },
      "source": [
        "## Setup Open AI API credentials"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l6ChC0K9e5JJ"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nm5l_l_7ioaV"
      },
      "source": [
        "## Connect to the LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3F6iaMmdinxH"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display, Markdown\n",
        "from langchain_openai import ChatOpenAI\n",
        "chatgpt = ChatOpenAI(model_name=\"gpt-5-mini\") #, temperature=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drMdp1XVs9Hv"
      },
      "source": [
        "## Create LCEL LLM Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKsCborniZxE"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# create a prompt template to accept user queries\n",
        "prompt_txt = \"{query}\"\n",
        "prompt_template = ChatPromptTemplate.from_template(prompt_txt)\n",
        "\n",
        "# the chain has been formatted for better readability\n",
        "# you could also write this as llmchain = prompt_template | chatgpt\n",
        "llmchain = (prompt_template | chatgpt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1JzZt0xtAUf"
      },
      "source": [
        "## Run the LLM Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Z-pC6PdjuFc",
        "outputId": "f4a67808-733b-45ad-d431-6e69abc826ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Short answer:\n",
            "\n",
            "- AI agent: a specific program or model that senses an environment and takes actions to achieve given tasks or objectives (e.g., an RL agent, a web-bot that fills forms, a chatbot that calls tools). It's a concrete instance with an action-perception loop.\n",
            "\n",
            "- Agentic AI: a descriptive term for systems that behave like agents in a stronger sense—autonomously pursuing goals over multiple steps, planning, adapting, and persisting with little human prompting. It highlights the system’s agent-like properties (higher autonomy, long-run goal pursuit, potential self-directed behavior), and is often used when discussing advanced or safety-relevant systems.\n",
            "\n",
            "One-line takeaway: \"AI agent\" names the actor; \"agentic AI\" describes the degree of autonomous, goal-directed agency that actor exhibits.\n"
          ]
        }
      ],
      "source": [
        "response = llmchain.invoke({'query' : 'Explain the difference between AI Agents and Agentic AI in short'})\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(response.content))"
      ],
      "metadata": {
        "id": "aR4X6n9ifQCD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "e6a80e2c-a079-4321-d778-7808dd67693e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Short answer:\n\n- AI agent: a specific program or model that senses an environment and takes actions to achieve given tasks or objectives (e.g., an RL agent, a web-bot that fills forms, a chatbot that calls tools). It's a concrete instance with an action-perception loop.\n\n- Agentic AI: a descriptive term for systems that behave like agents in a stronger sense—autonomously pursuing goals over multiple steps, planning, adapting, and persisting with little human prompting. It highlights the system’s agent-like properties (higher autonomy, long-run goal pursuit, potential self-directed behavior), and is often used when discussing advanced or safety-relevant systems.\n\nOne-line takeaway: \"AI agent\" names the actor; \"agentic AI\" describes the degree of autonomous, goal-directed agency that actor exhibits."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dbxxsqm8PsAl",
        "outputId": "3236edc5-890b-4bd6-b3bb-8053973b515d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='Short answer:\\n\\n- AI agent: a specific program or model that senses an environment and takes actions to achieve given tasks or objectives (e.g., an RL agent, a web-bot that fills forms, a chatbot that calls tools). It\\'s a concrete instance with an action-perception loop.\\n\\n- Agentic AI: a descriptive term for systems that behave like agents in a stronger sense—autonomously pursuing goals over multiple steps, planning, adapting, and persisting with little human prompting. It highlights the system’s agent-like properties (higher autonomy, long-run goal pursuit, potential self-directed behavior), and is often used when discussing advanced or safety-relevant systems.\\n\\nOne-line takeaway: \"AI agent\" names the actor; \"agentic AI\" describes the degree of autonomous, goal-directed agency that actor exhibits.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 492, 'prompt_tokens': 18, 'total_tokens': 510, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 320, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CaLCUFYn8OoGZQFnKsbNjH6T4Fr7U', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--5b54e263-bbcc-442c-977f-0c528dd18ccf-0', usage_metadata={'input_tokens': 18, 'output_tokens': 492, 'total_tokens': 510, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 320}})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = llmchain.invoke({'query' : 'Tabulate the differences between Traditional AI and Generative AI'})\n",
        "display(Markdown(response.content))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        },
        "id": "x1vG21oyPt8z",
        "outputId": "f01710a1-a554-49dd-f4a6-ce10c8b6aec1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "| Aspect | Traditional AI | Generative AI |\n|---|---:|---|\n| Definition | Systems that use algorithms to perform tasks, make decisions, or classify/predict based on rules or learned patterns. | Models that learn probability distributions over data to generate new, plausible content (text, images, audio, code, etc.). |\n| Primary goal | Accurate prediction, classification, optimization, decision-making. | Produce novel, coherent, and contextually appropriate content. |\n| Typical outputs | Labels, scores, decisions, recommendations, control signals. | Free-form content: text, images, audio, video, code, structured data. |\n| Core techniques | Classical ML (logistic regression, SVM, decision trees), rule-based systems, expert systems, reinforcement learning for control. | Deep generative models (transformers, VAEs, GANs, diffusion models, autoregressive models). |\n| Training objective | Minimize prediction/error (e.g., cross-entropy, MSE) for a defined target variable. | Model likelihood, reconstruction loss, adversarial loss, or diffusion denoising objectives to approximate data distribution. |\n| Data requirements | Labeled datasets for supervised tasks; structured features often suffice. | Large-scale, diverse unlabeled (or weakly labeled) datasets; benefits from massive-scale pretraining. |\n| Output determinism | Often deterministic or constrained; repeatable given same inputs and model state. | Typically probabilistic and may produce different outputs for same prompt; sampling introduces variability. |\n| Creativity/novelty | Limited — tends to reproduce learned patterns or rules. | High — designed to synthesize novel combinations and generate unseen content. |\n| Interpretability | Often more interpretable (especially simpler models); explainability methods established. | Generally less interpretable (large, opaque neural networks); explainability is an active research area. |\n| Evaluation metrics | Task-specific metrics (accuracy, precision/recall, F1, RMSE, AUC). | Both task metrics and human-centered evaluations (perplexity, BLEU/ROUGE, FID, human preference, factuality checks). |\n| Common applications | Fraud detection, predictive maintenance, classification, recommendation, control systems. | Text generation, image synthesis, code generation, creative content, conversational agents, data augmentation. |\n| Failure modes | Misclassification, overfitting, brittle rules, distribution shift. | Hallucination (fabricated facts), biased or toxic outputs, incoherence, overfitting to spurious patterns. |\n| Safety & risks | Bias and fairness concerns, but often easier to constrain outputs. | Amplified risks: hallucinations, misuse for disinformation, IP issues, harder to constrain. |\n| Control & steering | Rule constraints, explicit objective functions, conservative outputs. | Prompting, fine-tuning, RLHF, filters/safety layers, but control is probabilistic and imperfect. |\n| Resource needs | Can be lightweight depending on model; classical models often inexpensive to train/deploy. | Typically compute- and data-intensive to train; inference cost can also be high (large transformer models). |\n| Licensing & IP issues | Easier to trace training data and provenance; less generative plagiarism risk. | Complex IP and attribution concerns due to training on large web-scale corpora and content synthesis. |\n| Human oversight | Often used as decision support with clear thresholds for human-in-the-loop. | Strong need for human review, especially for high-stakes or factual content. |\n| Typical development cycle | Model design → feature engineering → training → evaluation → deployment. | Pretraining on massive data → fine-tuning/prompting → safety alignment → deployment and monitoring. |\n| Example systems | Decision trees, SVMs, rule engines, classical recommendation algorithms. | GPT, DALL·E/Stable Diffusion, Music LM, Codex, diffusion-based image models. |\n\nIf you want this in CSV, fewer/more comparison rows, or focused on a particular domain (healthcare, finance, etc.), tell me and I’ll adapt it."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xIJQxk8lQJAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AIpAQ8VQMWO",
        "outputId": "15b7160e-4259-491f-b951-17af117d602c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Aspect | Traditional AI | Generative AI |\n",
            "|---|---:|---|\n",
            "| Definition | Systems that use algorithms to perform tasks, make decisions, or classify/predict based on rules or learned patterns. | Models that learn probability distributions over data to generate new, plausible content (text, images, audio, code, etc.). |\n",
            "| Primary goal | Accurate prediction, classification, optimization, decision-making. | Produce novel, coherent, and contextually appropriate content. |\n",
            "| Typical outputs | Labels, scores, decisions, recommendations, control signals. | Free-form content: text, images, audio, video, code, structured data. |\n",
            "| Core techniques | Classical ML (logistic regression, SVM, decision trees), rule-based systems, expert systems, reinforcement learning for control. | Deep generative models (transformers, VAEs, GANs, diffusion models, autoregressive models). |\n",
            "| Training objective | Minimize prediction/error (e.g., cross-entropy, MSE) for a defined target variable. | Model likelihood, reconstruction loss, adversarial loss, or diffusion denoising objectives to approximate data distribution. |\n",
            "| Data requirements | Labeled datasets for supervised tasks; structured features often suffice. | Large-scale, diverse unlabeled (or weakly labeled) datasets; benefits from massive-scale pretraining. |\n",
            "| Output determinism | Often deterministic or constrained; repeatable given same inputs and model state. | Typically probabilistic and may produce different outputs for same prompt; sampling introduces variability. |\n",
            "| Creativity/novelty | Limited — tends to reproduce learned patterns or rules. | High — designed to synthesize novel combinations and generate unseen content. |\n",
            "| Interpretability | Often more interpretable (especially simpler models); explainability methods established. | Generally less interpretable (large, opaque neural networks); explainability is an active research area. |\n",
            "| Evaluation metrics | Task-specific metrics (accuracy, precision/recall, F1, RMSE, AUC). | Both task metrics and human-centered evaluations (perplexity, BLEU/ROUGE, FID, human preference, factuality checks). |\n",
            "| Common applications | Fraud detection, predictive maintenance, classification, recommendation, control systems. | Text generation, image synthesis, code generation, creative content, conversational agents, data augmentation. |\n",
            "| Failure modes | Misclassification, overfitting, brittle rules, distribution shift. | Hallucination (fabricated facts), biased or toxic outputs, incoherence, overfitting to spurious patterns. |\n",
            "| Safety & risks | Bias and fairness concerns, but often easier to constrain outputs. | Amplified risks: hallucinations, misuse for disinformation, IP issues, harder to constrain. |\n",
            "| Control & steering | Rule constraints, explicit objective functions, conservative outputs. | Prompting, fine-tuning, RLHF, filters/safety layers, but control is probabilistic and imperfect. |\n",
            "| Resource needs | Can be lightweight depending on model; classical models often inexpensive to train/deploy. | Typically compute- and data-intensive to train; inference cost can also be high (large transformer models). |\n",
            "| Licensing & IP issues | Easier to trace training data and provenance; less generative plagiarism risk. | Complex IP and attribution concerns due to training on large web-scale corpora and content synthesis. |\n",
            "| Human oversight | Often used as decision support with clear thresholds for human-in-the-loop. | Strong need for human review, especially for high-stakes or factual content. |\n",
            "| Typical development cycle | Model design → feature engineering → training → evaluation → deployment. | Pretraining on massive data → fine-tuning/prompting → safety alignment → deployment and monitoring. |\n",
            "| Example systems | Decision trees, SVMs, rule engines, classical recommendation algorithms. | GPT, DALL·E/Stable Diffusion, Music LM, Codex, diffusion-based image models. |\n",
            "\n",
            "If you want this in CSV, fewer/more comparison rows, or focused on a particular domain (healthcare, finance, etc.), tell me and I’ll adapt it.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dl33AtljQUzQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}